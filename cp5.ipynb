{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256,activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 10:06:23.369044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-27 10:06:23.412097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.785GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-27 10:06:23.413586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.785GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-27 10:06:23.413747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-27 10:06:23.415230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-27 10:06:23.416648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-27 10:06:23.416907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-27 10:06:23.418495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-27 10:06:23.419331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-27 10:06:23.422728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-27 10:06:23.425014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\n",
      "2021-10-27 10:06:23.425627: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-10-27 10:06:23.440933: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz\n",
      "2021-10-27 10:06:23.443445: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7a14000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-27 10:06:23.443479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-10-27 10:06:23.619847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556a1a12be30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-10-27 10:06:23.619893: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 3090, Compute Capability 8.6\n",
      "2021-10-27 10:06:23.619904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 3090, Compute Capability 8.6\n",
      "2021-10-27 10:06:23.621093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:17:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.785GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-27 10:06:23.623888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:65:00.0 name: GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.785GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2021-10-27 10:06:23.623950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-27 10:06:23.623973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-27 10:06:23.623994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-27 10:06:23.624014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-27 10:06:23.624034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-27 10:06:23.624054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-27 10:06:23.624076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-27 10:06:23.630912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1\n",
      "2021-10-27 10:06:23.630979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-10-27 10:06:23.635872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-27 10:06:23.635897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 \n",
      "2021-10-27 10:06:23.635907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N N \n",
      "2021-10-27 10:06:23.635915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N N \n",
      "2021-10-27 10:06:23.639236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 779 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:17:00.0, compute capability: 8.6)\n",
      "2021-10-27 10:06:23.641993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 21795 MB memory) -> physical GPU (device: 1, name: GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6)\n",
      "2021-10-27 10:09:54.954193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.42025387,  0.5844606 ,  0.4185487 , -0.03543741,  0.30877548,\n",
       "        -0.21616144,  0.23725063, -0.30998796, -0.03085215,  0.36529422],\n",
       "       [ 0.30915403,  0.09992593,  0.4133116 , -0.16274762, -0.12876947,\n",
       "        -0.15452962,  0.09960232, -0.06967045, -0.04102004, -0.02586354]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((2,20))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用`MLP`的父类`Block`的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数`params`（稍后将介绍）\n",
    "        super().__init__()\n",
    "        # Hidden layer\n",
    "        self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(units=10)  # Output layer\n",
    "\n",
    "    # 定义模型的正向传播，即如何根据输入`X`返回所需的模型输出\n",
    "    def call(self, X):\n",
    "        return self.out(self.hidden((X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.01892718,  0.03442106, -0.03709103, -0.25153875,  0.1339964 ,\n",
       "         0.04853793,  0.12294535,  0.03671088, -0.22283463, -0.20887223],\n",
       "       [ 0.14022581,  0.40567994, -0.19877303, -0.1979876 , -0.05517552,\n",
       "         0.04119499,  0.12078217,  0.04348309, -0.18448439, -0.4255119 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  5376      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 7,946\n",
      "Trainable params: 7,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(tf.keras.Model):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        self.modules = []\n",
    "        for block in args:\n",
    "            # 这里，`block`是`tf.keras.layers.Layer`子类的一个实例。\n",
    "            self.modules.append(block)\n",
    "\n",
    "    def call(self, X):\n",
    "        for module in self.modules:\n",
    "            X = module(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.13596225, -0.42076984,  0.4828717 , -0.11863811, -0.25491825,\n",
       "         0.17139563,  0.00105003,  0.02972568, -0.01912697,  0.25519523],\n",
       "       [ 0.43733844, -0.43543112,  0.29148492,  0.01902463, -0.47865397,\n",
       "         0.21552086,  0.14211564, -0.04099028, -0.11882308,  0.28752103]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(\n",
    "    tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # 使用`tf.constant`函数创建的随机权重参数在训练期间不会更新（即为常量参数）。\n",
    "        self.rand_weight = tf.constant(tf.random.uniform((20, 20)))\n",
    "        self.dense = tf.keras.layers.Dense(20, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = self.flatten(inputs)\n",
    "        # 使用创建的常量参数以及`relu`和`matmul`函数。\n",
    "        X = tf.nn.relu(tf.matmul(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数。\n",
    "        X = self.dense(X)\n",
    "        # 控制流\n",
    "        while tf.reduce_sum(tf.math.abs(X)) > 1:\n",
    "            X /= 2\n",
    "        return tf.reduce_sum(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7149376>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5126094>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = tf.keras.Sequential()\n",
    "        self.net.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "        self.net.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "        self.dense = tf.keras.layers.Dense(16, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(self.net(inputs))\n",
    "\n",
    "chimera = tf.keras.Sequential()\n",
    "chimera.add(NestMLP())\n",
    "chimera.add(tf.keras.layers.Dense(20))\n",
    "chimera.add(FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fixed_hidden_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  420       \n",
      "=================================================================\n",
      "Total params: 420\n",
      "Trainable params: 420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-1.6989639],\n",
       "       [-1.1149968]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "X = tf.random.uniform((2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'sequential_3/dense_13/kernel:0' shape=(4, 1) dtype=float32, numpy=\n",
      "array([[-1.0553765 ],\n",
      "       [-0.79944146],\n",
      "       [-0.9164586 ],\n",
      "       [-0.00261855]], dtype=float32)>, <tf.Variable 'sequential_3/dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(net.layers[2].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "<tf.Variable 'sequential_3/dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(type(net.layers[2].weights[1]))\n",
    "print(net.layers[2].weights[1])\n",
    "print(tf.convert_to_tensor(net.layers[2].weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'sequential_3/dense_12/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[ 0.8524328 , -0.42713472, -0.7695273 ,  0.7103122 ],\n",
      "       [ 0.2144013 ,  0.8100081 , -0.27583718,  0.76165444],\n",
      "       [ 0.55537564, -0.1186536 ,  0.30644757,  0.3617522 ],\n",
      "       [ 0.37697536,  0.00607699,  0.5920847 , -0.7321231 ]],\n",
      "      dtype=float32)>, <tf.Variable 'sequential_3/dense_12/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]\n",
      "[array([[ 0.8524328 , -0.42713472, -0.7695273 ,  0.7103122 ],\n",
      "       [ 0.2144013 ,  0.8100081 , -0.27583718,  0.76165444],\n",
      "       [ 0.55537564, -0.1186536 ,  0.30644757,  0.3617522 ],\n",
      "       [ 0.37697536,  0.00607699,  0.5920847 , -0.7321231 ]],\n",
      "      dtype=float32), array([0., 0., 0., 0.], dtype=float32), array([[-1.0553765 ],\n",
      "       [-0.79944146],\n",
      "       [-0.9164586 ],\n",
      "       [-0.00261855]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(net.layers[1].weights)\n",
    "print(net.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1(name):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4, activation=tf.nn.relu)],\n",
    "        name=name)\n",
    "\n",
    "def block2():\n",
    "    net = tf.keras.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add(block1(name=f'block-{i}'))\n",
    "    return net\n",
    "\n",
    "rgnet = tf.keras.Sequential()\n",
    "rgnet.add(block2())\n",
    "rgnet.add(tf.keras.layers.Dense(1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_5 (Sequential)    multiple                  80        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             multiple                  5         \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_4/sequential_5/block-1/dense_15/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.layers[0].layers[1].layers[1].weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'sequential_6/dense_19/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
       " array([[-0.02608244, -0.00242572,  0.00460067, -0.00565759],\n",
       "        [ 0.00571476, -0.00078479, -0.01786315,  0.01032325],\n",
       "        [ 0.01408292, -0.00457417,  0.00165934, -0.01139633],\n",
       "        [ 0.01077343,  0.00188405, -0.00669253,  0.00925974]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'sequential_6/dense_19/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        4, activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.01),\n",
    "        bias_initializer=tf.zeros_initializer()),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "\n",
    "net(X)\n",
    "net.weights[0], net.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'sequential_7/dense_21/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
       " array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=float32)>,\n",
       " <tf.Variable 'sequential_7/dense_21/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        4, activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.keras.initializers.Constant(1),\n",
    "        bias_initializer=tf.zeros_initializer()),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "net(X)\n",
    "net.weights[0], net.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'sequential_8/dense_23/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.4046015 ,  0.16566402, -0.6033228 ,  0.25067157],\n",
      "       [ 0.4784636 , -0.36495614,  0.19036931,  0.4109885 ],\n",
      "       [ 0.30405325,  0.08318692, -0.77716035, -0.25461942],\n",
      "       [-0.32151514, -0.80836165,  0.39931577, -0.47657326]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'sequential_8/dense_24/kernel:0' shape=(4, 1) dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        4,\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.keras.initializers.GlorotUniform()),\n",
    "    tf.keras.layers.Dense(\n",
    "        1, kernel_initializer=tf.keras.initializers.Constant(1)),\n",
    "])\n",
    "\n",
    "net(X)\n",
    "print(net.layers[1].weights[0])\n",
    "print(net.layers[2].weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'sequential_9/dense_25/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.       , -5.2362466, -8.197484 , -7.2174335],\n",
      "       [ 0.       , -6.728115 ,  0.       , -8.632565 ],\n",
      "       [-0.       , -0.       , -0.       ,  6.0986805],\n",
      "       [ 0.       , -6.94957  , -6.4328146,  0.       ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "class MyInit(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        data=tf.random.uniform(shape, -10, 10, dtype=dtype)\n",
    "        factor=(tf.abs(data) >= 5)\n",
    "        factor=tf.cast(factor, tf.float32)\n",
    "        return data * factor\n",
    "\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        4,\n",
    "        activation=tf.nn.relu,\n",
    "        kernel_initializer=MyInit()),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "net(X)\n",
    "print(net.layers[1].weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_9/dense_25/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[42.       , -4.2362466, -7.197484 , -6.2174335],\n",
       "       [ 1.       , -5.728115 ,  1.       , -7.6325645],\n",
       "       [ 1.       ,  1.       ,  1.       ,  7.0986805],\n",
       "       [ 1.       , -5.94957  , -5.4328146,  1.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[1].weights[0][:].assign(net.layers[1].weights[0] + 1)\n",
    "net.layers[1].weights[0][0, 0].assign(42)\n",
    "net.layers[1].weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# tf.keras的表现有点不同。它会自动删除重复层\n",
    "shared = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    shared,\n",
    "    shared,\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "net(X)\n",
    "# 检查参数是否不同\n",
    "print(len(net.layers) == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], []]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[net.layers[i].get_weights() for i in range(len(net.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20, 256), (256,), (256, 10), (10,)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((2, 20))\n",
    "net(X)\n",
    "[w.shape for w in net.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class CenteredLayer(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs - tf.reduce_mean(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([-2, -1,  0,  1,  2], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(tf.constant([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = tf.keras.Sequential([tf.keras.layers.Dense(128), CenteredLayer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.7252903e-09>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(tf.random.uniform((4, 8)))\n",
    "tf.reduce_mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, X_shape):\n",
    "        self.weight = self.add_weight(name='weight',\n",
    "            shape=[X_shape[-1], self.units],\n",
    "            initializer=tf.random_normal_initializer())\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units],\n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "    def call(self, X):\n",
    "        linear = tf.matmul(X, self.weight) + self.bias\n",
    "        return tf.nn.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0017721 ,  0.05793003, -0.03384516],\n",
       "        [ 0.05414852,  0.05358556,  0.07671374],\n",
       "        [-0.0361996 , -0.04363196,  0.04037216],\n",
       "        [ 0.04978222,  0.03155075,  0.12934138],\n",
       "        [ 0.08498754, -0.0268233 , -0.03434233]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = MyDense(3)\n",
    "dense(tf.random.uniform((2, 5)))\n",
    "dense.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.08682563, 0.00440838, 0.06056979],\n",
       "       [0.05445284, 0.00501781, 0.02500721]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense(tf.random.uniform((2, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.00783756],\n",
       "       [0.01797368]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential([MyDense(8), MyDense(1)])\n",
    "net(tf.random.uniform((2, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.range(4)\n",
    "np.save('x-file.npy', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = np.load('x-file.npy', allow_pickle=True)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3.]), array([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.zeros(4)\n",
    "np.save('xy-files.npy', [x, y])\n",
    "x2, y2 = np.load('xy-files.npy', allow_pickle=True)\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'x': <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>, 'y': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "np.save('mydict.npy', mydict)\n",
    "mydict2 = np.load('mydict.npy', allow_pickle=True)\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.hidden = tf.keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.hidden(x)\n",
    "        return self.out(x)\n",
    "\n",
    "net = MLP()\n",
    "X = tf.random.uniform((2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_weights('mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7b339dfb10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_weights('mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 27 10:36:43 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    On   | 00000000:17:00.0 Off |                  N/A |\r\n",
      "|  0%   56C    P8    27W / 370W |   1218MiB / 24268MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 3090    On   | 00000000:65:00.0 Off |                  N/A |\r\n",
      "|  0%   45C    P8    33W / 370W |    825MiB / 24265MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      3582      C   ...a3/envs/tf-gpu/bin/python     1215MiB |\r\n",
      "|    0   N/A  N/A     16754      C   ...3/envs/xgb_gpu/bin/python        0MiB |\r\n",
      "|    1   N/A  N/A      3582      C   ...a3/envs/tf-gpu/bin/python      255MiB |\r\n",
      "|    1   N/A  N/A     16754      C   ...3/envs/xgb_gpu/bin/python      567MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab07a1c10>,\n",
       " <tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab07a1350>,\n",
       " <tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab07a1d10>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.device('/CPU:0'), tf.device('/GPU:0'), tf.device('/GPU:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab07696d0>,\n",
       " <tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab07697d0>,\n",
       " [<tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab0769810>,\n",
       "  <tensorflow.python.eager.context._EagerDeviceContext at 0x7f7ab0769890>])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\"\"\"\n",
    "    if len(tf.config.experimental.list_physical_devices('GPU')) >= i + 1:\n",
    "        return tf.device(f'/GPU:{i}')\n",
    "    return tf.device('/CPU:0')\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。\"\"\"\n",
    "    num_gpus = len(tf.config.experimental.list_physical_devices('GPU'))\n",
    "    devices = [tf.device(f'/GPU:{i}') for i in range(num_gpus)]\n",
    "    return devices if devices else [tf.device('/CPU:0')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with try_gpu():\n",
    "    X = tf.ones((2, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.08526587, 0.8208443 , 0.93755734],\n",
       "       [0.89818895, 0.7838323 , 0.13732052]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with try_gpu(1):\n",
    "    Y = tf.random.uniform((2, 3))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with try_gpu(1):\n",
    "    Z = X\n",
    "print(X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1.0852659, 1.8208443, 1.9375573],\n",
       "       [1.898189 , 1.7838323, 1.1373205]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with try_gpu(1):\n",
    "    Z2 = Z\n",
    "Z2 is Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    net = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.2582593],\n",
       "       [0.2582593]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].weights[0].device, net.layers[0].weights[1].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
